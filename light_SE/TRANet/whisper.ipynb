{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import librosa\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-large-v3\")\n",
    "\n",
    "def transcribe(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    y = y.astype(np.float32)\n",
    "    y /= np.max(np.abs(y))\n",
    "    \n",
    "    return transcriber({\"sampling_rate\": sr, \"raw\": y}, generate_kwargs={\"language\" : \"korean\"})[\"text\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b9c199a8424b1e9564c52b87fb1825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thk/anaconda3/envs/SSI/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:480: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "You have passed language=korean, but also have set `forced_decoder_ids` to [[1, None], [2, 50360]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of language=korean.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 청소 모두 설명해줘.\n",
      " 청소 시작방법 설명해줘\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclean2_transcribe.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m tqdm(glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(audio_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m))):\n\u001b[0;32m---> 11\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28mprint\u001b[39m(text)\n\u001b[1;32m     13\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     11\u001b[0m y \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(np\u001b[38;5;241m.\u001b[39mabs(y))\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtranscriber\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msampling_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlanguage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkorean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/SSI/lib/python3.10/site-packages/transformers/pipelines/automatic_speech_recognition.py:284\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline.__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    223\u001b[0m     inputs: Union[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    225\u001b[0m ):\n\u001b[1;32m    226\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m    Transcribe the audio sequence(s) given as inputs to text. See the [`AutomaticSpeechRecognitionPipeline`]\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    documentation for more information.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m                `\"\".join(chunk[\"text\"] for chunk in output[\"chunks\"])`.\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/SSI/lib/python3.10/site-packages/transformers/pipelines/base.py:1246\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ChunkPipeline):\n\u001b[0;32m-> 1246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "File \u001b[0;32m~/anaconda3/envs/SSI/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/SSI/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:269\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 269\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m~/anaconda3/envs/SSI/lib/python3.10/site-packages/transformers/pipelines/base.py:1161\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1160\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1161\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/SSI/lib/python3.10/site-packages/transformers/pipelines/automatic_speech_recognition.py:504\u001b[0m, in \u001b[0;36mAutomaticSpeechRecognitionPipeline._forward\u001b[0;34m(self, model_inputs, return_timestamps, **generate_kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    502\u001b[0m             generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_frames\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_frames\n\u001b[0;32m--> 504\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;66;03m# whisper longform generation stores timestamps in \"segments\"\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_timestamps \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq2seq_whisper\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/SSI/lib/python3.10/site-packages/transformers/models/whisper/generation_whisper.py:587\u001b[0m, in \u001b[0;36mWhisperGenerationMixin.generate\u001b[0;34m(self, input_features, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, return_timestamps, task, language, is_multilingual, prompt_ids, prompt_condition_type, condition_on_prev_tokens, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, num_segment_frames, attention_mask, time_precision, return_token_timestamps, return_segments, return_dict_in_generate, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_new_tokens \u001b[38;5;241m+\u001b[39m decoder_input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmax_target_positions:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe length of `decoder_input_ids` equal `prompt_ids` plus special start tokens is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdecoder_input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, and the `max_new_tokens` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_new_tokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Thus, the combined length of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mso that their combined length is less than \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmax_target_positions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m     )\n\u001b[0;32m--> 587\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix_allowed_tokens_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefix_allowed_tokens_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mreturn_token_timestamps \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(generation_config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malignment_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    599\u001b[0m     outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_timestamps\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_token_timestamps(\n\u001b[1;32m    600\u001b[0m         outputs, generation_config\u001b[38;5;241m.\u001b[39malignment_heads, num_frames\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_frames\n\u001b[1;32m    601\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/SSI/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/SSI/lib/python3.10/site-packages/transformers/generation/utils.py:1696\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1690\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_attention_mask_for_generation(\n\u001b[1;32m   1691\u001b[0m         inputs_tensor, generation_config\u001b[38;5;241m.\u001b[39mpad_token_id, generation_config\u001b[38;5;241m.\u001b[39meos_token_id\n\u001b[1;32m   1692\u001b[0m     )\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[1;32m   1695\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001b[39;00m\n\u001b[0;32m-> 1696\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\n\u001b[1;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1700\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[1;32m   1701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n",
      "File \u001b[0;32m~/anaconda3/envs/SSI/lib/python3.10/site-packages/transformers/generation/utils.py:539\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001b[0m\n\u001b[1;32m    537\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    538\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[0;32m--> 539\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoder_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n",
      "File \u001b[0;32m~/anaconda3/envs/SSI/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/SSI/lib/python3.10/site-packages/transformers/models/whisper/modeling_whisper.py:1214\u001b[0m, in \u001b[0;36mWhisperEncoder.forward\u001b[0;34m(self, input_features, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1206\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1207\u001b[0m             encoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1208\u001b[0m             hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             output_attentions,\n\u001b[1;32m   1212\u001b[0m         )\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1214\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1221\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/anaconda3/envs/SSI/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/SSI/lib/python3.10/site-packages/transformers/models/whisper/modeling_whisper.py:770\u001b[0m, in \u001b[0;36mWhisperEncoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    768\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    769\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn_layer_norm(hidden_states)\n\u001b[0;32m--> 770\u001b[0m hidden_states, attn_weights, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    776\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    777\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/envs/SSI/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "path = \"/home/nas3/user/thk/TRANet/DB/eval\"\n",
    "\n",
    "audio_path = os.path.join(path, \"clean\")\n",
    "\n",
    "with open(os.path.join(path, \"clean2_transcribe.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    for file in tqdm(glob.glob(os.path.join(audio_path, \"*.wav\"))):\n",
    "        text = transcribe(file)\n",
    "        print(text)\n",
    "        f.write(f\"{os.path.basename(file)}: {text}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'001_female_30s_seoul-01': '청소 모드 설명해줘.',\n",
       " '001_female_30s_seoul-02': '청소 시작방법 설명해줘',\n",
       " '001_female_30s_seoul-03': '꼼모드 설명해줘',\n",
       " '001_female_30s_seoul-04': '집중 모드 설명해줘.',\n",
       " '001_female_30s_seoul-05': '지그재그 모드 설명해줘.',\n",
       " '001_female_30s_seoul-06': '반복모드 설명해줘',\n",
       " '001_female_30s_seoul-07': '스마트 터보 모드 설명해줘.',\n",
       " '001_female_30s_seoul-08': '터보 모드 설명해줘.',\n",
       " '001_female_30s_seoul-09': '청소 예약 설명해줘',\n",
       " '001_female_30s_seoul-10': '스마트 기능 설명해줘',\n",
       " '001_female_30s_seoul-11': '청소 다이어리 설명해줘.',\n",
       " '001_female_30s_seoul-12': '스마트 진단 설명해줘',\n",
       " '001_female_30s_seoul-13': '소프트웨어 업데이트 설명해줘',\n",
       " '001_female_30s_seoul-14': '뷰어 잠금 설명해줘.',\n",
       " '001_female_30s_seoul-15': '홈 뷰 설명해줘',\n",
       " '001_female_30s_seoul-16': '홈가드 설명해줘',\n",
       " '001_female_30s_seoul-17': '새 도면 그리기 설명해줘',\n",
       " '001_female_30s_seoul-18': '선택 영역 청소 설명해줘.',\n",
       " '001_female_30s_seoul-19': '청소 금지 영역 설명해줘',\n",
       " '001_female_30s_seoul-20': '서비스 센터 알려줘',\n",
       " '001_female_30s_seoul-21': '꼼꼼 모드 설정해줘.',\n",
       " '001_female_30s_seoul-22': '집중 모드 설정해줘',\n",
       " '001_female_30s_seoul-23': '지그재그 모드 설정해줘.',\n",
       " '001_female_30s_seoul-24': '반복 모드 설정해줘',\n",
       " '001_female_30s_seoul-25': '반복 모드 해제해줘',\n",
       " '001_female_30s_seoul-26': '스마트 터보 모드 설정해줘.',\n",
       " '001_female_30s_seoul-27': '스마트 터보 모드 해제해줘',\n",
       " '001_female_30s_seoul-28': '터보 모드 설정해줘.',\n",
       " '001_female_30s_seoul-29': '터버 모드 해제해줘.',\n",
       " '001_female_30s_seoul-30': '2시 청소 예약해 줘.',\n",
       " '001_female_30s_seoul-31': '매일 2시 청소 예약해줘.',\n",
       " '001_female_30s_seoul-32': '청소 예약 취소해줘.',\n",
       " '001_female_30s_seoul-34': '거실 청소해줘.',\n",
       " '001_female_30s_seoul-35': '금지 영역 설정해줘',\n",
       " '001_female_30s_seoul-33': '새 도면 그려줘.',\n",
       " '001_female_30s_seoul-36': '꼼꼼 모드로 청소해줘.',\n",
       " '001_female_30s_seoul-37': '지그재그 모드로 청소해줘.',\n",
       " '001_female_30s_seoul-38': '집중 모드로 청소해줘.',\n",
       " '001_female_30s_seoul-39': '구석 신경 써서 청소해줘.',\n",
       " '001_female_30s_seoul-40': '거실 꼼꼼 모드로 청소해줘.',\n",
       " '001_female_30s_seoul-41': '침실 지그재그 모드로 청소해줘.',\n",
       " '001_female_30s_seoul-42': '서재 구석 신경 써서 청소해줘.',\n",
       " '001_female_30s_seoul-43': '청소 이력 확인해줘.',\n",
       " '001_female_30s_seoul-45': '업데이트해줘',\n",
       " '001_female_30s_seoul-44': '업데이트 확인해줘',\n",
       " '001_female_30s_seoul-47': '청소 시작해줘.',\n",
       " '001_female_30s_seoul-46': '스마트 진단 시작해줘.',\n",
       " '001_female_30s_seoul-48': '청소 정지해줘.',\n",
       " '001_female_30s_seoul-49': '충전 시작해줘.',\n",
       " '001_female_30s_seoul-50': '뷰어 잠금 설정해줘',\n",
       " '001_female_30s_seoul-51': '뷰어 잠금 해제해줘',\n",
       " '001_female_30s_seoul-52': '홈가드 시작해줘.',\n",
       " '001_female_30s_seoul-53': '2시 홈가드 예약해 줘.',\n",
       " '001_female_30s_seoul-54': '매일 2시 홈가드 예약해줘.',\n",
       " '001_female_30s_seoul-55': '홈가드 예약 취소해줘.',\n",
       " '001_female_30s_seoul-56': '음소거 설정해줘.',\n",
       " '004_female_30s_gyeonggi-01': '청소 모드 설명해줘.',\n",
       " '004_female_30s_gyeonggi-02': '청소 시작 방법 설명해 줘.',\n",
       " '004_female_30s_gyeonggi-03': '꼼꼼 모드 설명해 줘',\n",
       " '004_female_30s_gyeonggi-04': '집중 모드 설명해줘.',\n",
       " '004_female_30s_gyeonggi-05': '지그재그 모드 설명해줘.',\n",
       " '004_female_30s_gyeonggi-06': '반복 모드 설명해줘.',\n",
       " '004_female_30s_gyeonggi-07': '스마트 터보 모드 설명해줘.',\n",
       " '004_female_30s_gyeonggi-08': '터보 모드 설명해줘.',\n",
       " '004_female_30s_gyeonggi-09': '청소 예약 설명해줘.',\n",
       " '004_female_30s_gyeonggi-10': '스마트 기능 설명해줘.',\n",
       " '004_female_30s_gyeonggi-11': '청소 다이어리 설명해줘.',\n",
       " '004_female_30s_gyeonggi-12': '스마트 진단 설명해줘.',\n",
       " '004_female_30s_gyeonggi-13': '소프트웨어 업데이트 설명해줘.',\n",
       " '004_female_30s_gyeonggi-14': '뷰어 잠금 설명해줘',\n",
       " '004_female_30s_gyeonggi-15': '홈뷰 설명해줘.',\n",
       " '004_female_30s_gyeonggi-16': '홈가드 설명해줘',\n",
       " '004_female_30s_gyeonggi-17': '새 도면 그리기 설명해줘.',\n",
       " '004_female_30s_gyeonggi-18': '선택 영역 청소 설명해줘',\n",
       " '004_female_30s_gyeonggi-19': '청소금지영역 설명해줘',\n",
       " '004_female_30s_gyeonggi-21': '꼼꼼 모드 설정해줘',\n",
       " '004_female_30s_gyeonggi-22': '집중 모드 설정해줘.',\n",
       " '004_female_30s_gyeonggi-23': '지그재그 모드 설정해줘.',\n",
       " '004_female_30s_gyeonggi-20': '서비스 센터 알려줘',\n",
       " '004_female_30s_gyeonggi-24': '반복 모드 설정해줘.',\n",
       " '004_female_30s_gyeonggi-25': '반복 모드 해제해줘',\n",
       " '004_female_30s_gyeonggi-26': '스마트 터보 모드 설정해줘.',\n",
       " '004_female_30s_gyeonggi-28': '터보 모드 설정해줘.',\n",
       " '004_female_30s_gyeonggi-27': '스마트 터보 모드 해제해줘.',\n",
       " '004_female_30s_gyeonggi-29': '터보 모드 해제해줘.',\n",
       " '004_female_30s_gyeonggi-30': '2시 청소 예약해 줘.',\n",
       " '004_female_30s_gyeonggi-32': '청소 예약 취소해줘',\n",
       " '004_female_30s_gyeonggi-31': '매일 2시 청소 예약해 줘.',\n",
       " '004_female_30s_gyeonggi-33': '새 도면 그려줘.',\n",
       " '004_female_30s_gyeonggi-34': '거실 청소해줘.',\n",
       " '004_female_30s_gyeonggi-35': '금지 영역 설정해 줘.',\n",
       " '004_female_30s_gyeonggi-36': '꼼꼼 모드로 청소해줘.',\n",
       " '004_female_30s_gyeonggi-37': '지그재그 모드로 청소해줘!',\n",
       " '004_female_30s_gyeonggi-38': '집중 모드로 청소해줘.',\n",
       " '004_female_30s_gyeonggi-39': '구석 신경 써서 청소해 줘.',\n",
       " '004_female_30s_gyeonggi-40': '거실 꼼꼼 모드로 청소해줘.',\n",
       " '004_female_30s_gyeonggi-41': '침실 지그재그 모드로 청소해 줘.',\n",
       " '004_female_30s_gyeonggi-43': '청소 이력 확인해줘.',\n",
       " '004_female_30s_gyeonggi-44': '업데이트 확인해줘!',\n",
       " '004_female_30s_gyeonggi-42': '서재, 구석 신경 써서 청소해 줘.',\n",
       " '004_female_30s_gyeonggi-45': '업데이트해줘.',\n",
       " '004_female_30s_gyeonggi-46': '스마트 진단 시작해줘.',\n",
       " '004_female_30s_gyeonggi-47': '청소 시작해줘.',\n",
       " '004_female_30s_gyeonggi-48': '청소 정지해줘.',\n",
       " '004_female_30s_gyeonggi-50': '뷰어 잠금 설정해줘.',\n",
       " '004_female_30s_gyeonggi-51': '뷰어 잠금 해제해줘',\n",
       " '004_female_30s_gyeonggi-49': '충전 시작해줘.',\n",
       " '004_female_30s_gyeonggi-52': '홈가드 시작해줘.',\n",
       " '004_female_30s_gyeonggi-53': '2시 홈가드 예약해줘.',\n",
       " '004_female_30s_gyeonggi-54': '매일 2시 홈가드 예약해 줘.',\n",
       " '004_female_30s_gyeonggi-55': '홈가드 예약 취소해줘',\n",
       " '004_female_30s_gyeonggi-56': '음소거 설정해 줘.',\n",
       " '007_male_20s_gyeongsang-01': '청소모드 설명해줘',\n",
       " '007_male_20s_gyeongsang-02': '청소 시작 방법 설명해줘',\n",
       " '007_male_20s_gyeongsang-03': '꼼꼼 모드 설명해줘',\n",
       " '007_male_20s_gyeongsang-04': '집중 모드 설명해줘.',\n",
       " '007_male_20s_gyeongsang-05': '지그재그 모드 설명해줘',\n",
       " '007_male_20s_gyeongsang-06': '반복 모드 설명해줘.',\n",
       " '007_male_20s_gyeongsang-07': '스마트 터보 모드 설명해줘',\n",
       " '007_male_20s_gyeongsang-08': '터보 모드 설명해줘.',\n",
       " '007_male_20s_gyeongsang-09': '청소 예약 설명해줘.',\n",
       " '007_male_20s_gyeongsang-10': '스마트 기능 설명해줘.',\n",
       " '007_male_20s_gyeongsang-12': '스마트 진단 설명해줘.',\n",
       " '007_male_20s_gyeongsang-11': '청소 다이어리 설명해줘.',\n",
       " '007_male_20s_gyeongsang-13': '소프트웨어 업데이트 설명해줘.',\n",
       " '007_male_20s_gyeongsang-14': '뷰어 잠금 설명해줘',\n",
       " '007_male_20s_gyeongsang-15': '홈뷰 설명해줘.',\n",
       " '007_male_20s_gyeongsang-16': '홈가드 설명해줘',\n",
       " '007_male_20s_gyeongsang-17': '새 도면 그리기 설명해줘.',\n",
       " '007_male_20s_gyeongsang-18': '선택 영역 청소 설명해줘.',\n",
       " '007_male_20s_gyeongsang-19': '청소 금지 영역 설명해줘.',\n",
       " '007_male_20s_gyeongsang-20': '서비스 센터 알려줘.',\n",
       " '007_male_20s_gyeongsang-21': '꼼꼼 모드 설정해줘.',\n",
       " '007_male_20s_gyeongsang-22': '집중 모드 설정해줘.',\n",
       " '007_male_20s_gyeongsang-23': '지그재그 모드 설정해줘.',\n",
       " '007_male_20s_gyeongsang-24': '반복 모드 설정해줘.',\n",
       " '007_male_20s_gyeongsang-26': '스마트 터보 모드 설정해줘.',\n",
       " '007_male_20s_gyeongsang-25': '반복 모드 해제해줘.',\n",
       " '007_male_20s_gyeongsang-27': '스마트 터보 모드 해제해줘.',\n",
       " '007_male_20s_gyeongsang-28': '터보 모드 설정해줘',\n",
       " '007_male_20s_gyeongsang-29': '터보 모드 해제해줘',\n",
       " '007_male_20s_gyeongsang-30': '2시 청소 예약해줘.',\n",
       " '007_male_20s_gyeongsang-31': '매일 2시 청소 예약해줘.',\n",
       " '007_male_20s_gyeongsang-32': '청소 예약 취소해줘',\n",
       " '007_male_20s_gyeongsang-33': '새 도면 그려줘.',\n",
       " '007_male_20s_gyeongsang-35': '금지 영역 설정해줘.',\n",
       " '007_male_20s_gyeongsang-36': '꼼꼼 모드로 청소해 줘.',\n",
       " '007_male_20s_gyeongsang-34': '거실 청소해 줘.',\n",
       " '007_male_20s_gyeongsang-37': '지그재그 모드로 청소해줘.',\n",
       " '007_male_20s_gyeongsang-38': '집중 모드로 청소해줘.',\n",
       " '007_male_20s_gyeongsang-39': '구석 신경 써서 청소해 줘.',\n",
       " '007_male_20s_gyeongsang-40': '거실 꼼꼼 모드로 청소해줘.',\n",
       " '007_male_20s_gyeongsang-42': '서재 구석 신경 써서 청소해줘.',\n",
       " '007_male_20s_gyeongsang-43': '청소 이력 확인해줘.',\n",
       " '007_male_20s_gyeongsang-41': '침실 지그재그 모드로 청소해줘.',\n",
       " '007_male_20s_gyeongsang-44': '업데이트 확인해줘',\n",
       " '007_male_20s_gyeongsang-45': '업데이트해줘.',\n",
       " '007_male_20s_gyeongsang-46': '스마트 진단 시작해줘.',\n",
       " '007_male_20s_gyeongsang-47': '청소 시작해줘',\n",
       " '007_male_20s_gyeongsang-48': '청소 정지해줘.',\n",
       " '007_male_20s_gyeongsang-50': '뷰어 잠금 설정해줘.',\n",
       " '007_male_20s_gyeongsang-49': '충전 시작해줘.',\n",
       " '007_male_20s_gyeongsang-51': '뷰어 잠금 해제해줘.',\n",
       " '007_male_20s_gyeongsang-53': '2시 홈가드 예약해줘.',\n",
       " '007_male_20s_gyeongsang-52': '홈가드 시작해줘',\n",
       " '007_male_20s_gyeongsang-54': '매일 두 시 홈가드 예약해줘.',\n",
       " '007_male_20s_gyeongsang-56': '음소거 설정해줘.',\n",
       " '007_male_20s_gyeongsang-55': '홈가드 예약 취소해줘.',\n",
       " '009_male_40s_seoul-02': '청소 시작 방법 설명해줘.',\n",
       " '009_male_40s_seoul-01': '청소 모드 설명해줘.',\n",
       " '009_male_40s_seoul-04': '집중 모드 설명해줘.',\n",
       " '009_male_40s_seoul-03': '꼼꼼 모드 설명해줘.',\n",
       " '009_male_40s_seoul-05': '지그재그 모드 설명해줘.',\n",
       " '009_male_40s_seoul-06': '반복 모드 설명해줘',\n",
       " '009_male_40s_seoul-08': '스마트 터보 모드 설명해줘.',\n",
       " '009_male_40s_seoul-07': '반복 모드 설명해줘',\n",
       " '009_male_40s_seoul-09': '터보 모드 설명해줘.',\n",
       " '009_male_40s_seoul-10': '청소 예약 설명해줘.',\n",
       " '009_male_40s_seoul-11': '스마트 기능 설명해줘.',\n",
       " '009_male_40s_seoul-12': '청소 다이어리 설명해줘.',\n",
       " '009_male_40s_seoul-13': '스마트 진단 설명해줘.',\n",
       " '009_male_40s_seoul-14': '소프트웨어 업데이트 설명해 줘',\n",
       " '009_male_40s_seoul-16': '홈뷰 설명해줘.',\n",
       " '009_male_40s_seoul-15': '뷰어 잠금 설명해줘',\n",
       " '009_male_40s_seoul-17': '홈가드 설명해줘.',\n",
       " '009_male_40s_seoul-18': '새 도면 그리기 설명해줘.',\n",
       " '009_male_40s_seoul-19': '선택 영역 청소 설명해줘.',\n",
       " '009_male_40s_seoul-20': '청소 금지 영역 설명해줘.',\n",
       " '009_male_40s_seoul-21': '서비스센터 알려줘',\n",
       " '009_male_40s_seoul-22': '꼼꼼 모드 설정해줘.',\n",
       " '009_male_40s_seoul-23': '집중 모드 설정해줘.',\n",
       " '009_male_40s_seoul-25': '반복 모드 설정해줘.',\n",
       " '009_male_40s_seoul-24': '지그재그 모드 설정해줘.',\n",
       " '009_male_40s_seoul-26': '반복 모드 해제해줘.',\n",
       " '009_male_40s_seoul-28': '스마트 터보 모드 해제해줘.',\n",
       " '009_male_40s_seoul-27': '스마트 터보 모드 설정해줘.',\n",
       " '009_male_40s_seoul-29': '터보 모드 설정해줘.',\n",
       " '009_male_40s_seoul-30': '터보 모드 해제해줘.',\n",
       " '009_male_40s_seoul-31': '2시 청소 예약해줘',\n",
       " '009_male_40s_seoul-32': '매일 2시 청소 예약해 줘.',\n",
       " '009_male_40s_seoul-33': '청소 예약 취소해줘.',\n",
       " '009_male_40s_seoul-34': '새 도면 그려줘.',\n",
       " '009_male_40s_seoul-35': '거실 청소해줘.',\n",
       " '009_male_40s_seoul-36': '금지 영역 설정해줘.',\n",
       " '009_male_40s_seoul-37': '꼼꼼 모드로 청소해줘.',\n",
       " '009_male_40s_seoul-39': '집중 모드로 청소해줘.',\n",
       " '009_male_40s_seoul-40': '구석 신경 써서 청소해줘.',\n",
       " '009_male_40s_seoul-38': '지그재그 모드로 청소해줘',\n",
       " '009_male_40s_seoul-41': '거실 꼼꼼 모드로 청소해줘.',\n",
       " '009_male_40s_seoul-42': '침실 지그재그 모드로 청소해줘.',\n",
       " '009_male_40s_seoul-43': '서재 구석 신경 써서 청소해줘.',\n",
       " '009_male_40s_seoul-44': '청소 이력 확인해 줘.',\n",
       " '009_male_40s_seoul-45': '업데이트 확인해줘.',\n",
       " '009_male_40s_seoul-46': '업데이트 해줘',\n",
       " '009_male_40s_seoul-47': '스마트 진단 시작해줘!',\n",
       " '009_male_40s_seoul-48': '청소 시작해줘.',\n",
       " '009_male_40s_seoul-49': '청소 정지해줘',\n",
       " '009_male_40s_seoul-50': '충전 시작해줘',\n",
       " '009_male_40s_seoul-51': '뷰어 잠금 설정해줘',\n",
       " '009_male_40s_seoul-52': '뷰어 잠금 해제해줘.',\n",
       " '009_male_40s_seoul-53': '홈가드 시작해줘',\n",
       " '009_male_40s_seoul-54': '2시 홈가드 예약해 줘.',\n",
       " '009_male_40s_seoul-55': '매일 2시 홈가드 예약해줘.',\n",
       " '009_male_40s_seoul-56': '홈가드 예약 취소해줘.',\n",
       " '009_male_40s_seoul-57': '음소거 설정해줘.'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_transcribe = {}\n",
    "label_txt = \"/home/nas3/user/thk/TRANet/DB/eval/label_transcribe.txt\"\n",
    "\n",
    "with open(label_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        label_transcribe[line[0].split(\"_Noise\")[0]] = line[1].lstrip()\n",
    "    f.close()\n",
    "label_transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.125, 0.0, 0.14285714285714285, 0.0, 0.1, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "0.009656244989578322\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import src.utils.whisper_metric as whisper_metric\n",
    "\n",
    "CER = whisper_metric.CharacterErrorRate()\n",
    "CER_result = []\n",
    "\n",
    "compare_txt = \"/home/nas3/user/thk/TRANet/DB/eval/clean_transcribe.txt\"\n",
    "\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.4, 2.2857142857142856, 1.0, 1.2, 1.0, 2.0, 1.0, 3.0, 0.8888888888888888, 1.0, 1.8888888888888888, 0.6923076923076923, 1.375, 2.6666666666666665, 1.2857142857142858, 66.6, 1.0, 1.0, 1.125, 0.875, 1.375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.75, 1.25, 0.4, 2.375, 1.1666666666666667, 0.375, 0.6666666666666666, 1.2222222222222223, 1.6363636363636365, 2.111111111111111, 1.0, 1.0, 0.9230769230769231, 1.0, 1.0, 1.0, 1.0, 1.0, 2.4444444444444446, 3.6666666666666665, 1.0, 1.0, 1.0, 0.7142857142857143, 2.111111111111111, 0.9090909090909091, 0.7777777777777778, 1.1428571428571428, 1.0, 1.9, 1.125, 0.0, 1.0, 1.625, 0.9090909090909091, 0.875, 1.25, 1.0, 0.5, 1.0, 1.2307692307692308, 1.0, 1.0, 0.5714285714285714, 1.3, 1.0, 0.0, 1.0, 0.5, 0.0, 0.375, 1.0, 0.875, 1.1818181818181819, 1.625, 0.7272727272727273, 0.875, 0.5, 0.625, 0.6, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6363636363636364, 1.0, 1.4, 0.18181818181818182, 1.6923076923076923, 2.125, 0.875, 1.3333333333333333, 1.0, 0.5555555555555556, 1.0, 1.0, 0.125, 1.0, 0.5, 0.5714285714285714, 1.4444444444444444, 0.45454545454545453, 1.5555555555555556, 1.1428571428571428, 2.375, 1.9, 1.0, 0.5, 1.0, 1.375, 1.0, 1.0, 0.75, 0.8888888888888888, 0.6666666666666666, 0.9, 1.0, 1.0, 1.0, 0.8571428571428571, 1.5, 1.4, 1.0, 1.0, 2.0, 2.375, 1.0, 1.0, 1.0, 1.0, 1.9090909090909092, 1.0, 1.125, 1.375, 1.0, 1.0, 1.5, 0.25, 0.7777777777777778, 1.0, 1.0, 1.2222222222222223, 1.0, 0.9090909090909091, 1.0, 1.0, 1.4615384615384615, 1.0, 37.0, 1.5555555555555556, 0.8333333333333334, 1.6666666666666667, 1.0, 1.8333333333333333, 0.75, 1.0, 1.1428571428571428, 1.0, 0.7142857142857143, 1.0, 1.3, 1.5, 0.875, 2.375, 1.7, 0.75, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 4.333333333333333, 1.0, 1.0, 2.1, 1.1, 0.8, 1.0, 2.375, 1.25, 1.875, 1.2, 1.0, 1.0, 1.0, 1.0, 1.125, 2.0, 0.7, 1.0, 3.1666666666666665, 1.0, 1.25, 1.0, 2.111111111111111, 0.9, 1.0, 1.1818181818181819, 1.0, 1.1666666666666667, 1.75, 2.375, 1.0, 1.3333333333333333, 1.1666666666666667, 1.0, 1.5, 1.125, 0.875, 0.7142857142857143, 2.111111111111111, 0.8181818181818182, 0.8888888888888888, 1.8571428571428572]\n",
      "1.6306374859708195\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/DB/eval/noisy_transcribe.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.4, 2.2857142857142856, 1.0, 1.2, 1.0, 2.0, 1.0, 3.0, 0.8888888888888888, 1.0, 1.8888888888888888, 0.6923076923076923, 1.375, 2.6666666666666665, 1.2857142857142858, 66.6, 1.0, 1.0, 1.125, 0.875, 1.375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.75, 1.25, 0.4, 2.375, 1.1666666666666667, 0.375, 0.6666666666666666, 1.2222222222222223, 1.6363636363636365, 2.111111111111111, 1.0, 1.0, 0.9230769230769231, 1.0, 1.0, 1.0, 1.0, 1.0, 2.4444444444444446, 3.6666666666666665, 1.0, 1.0, 1.0, 0.7142857142857143, 2.111111111111111, 0.9090909090909091, 0.7777777777777778, 1.1428571428571428, 1.0, 1.9, 1.125, 0.0, 1.0, 1.625, 0.9090909090909091, 0.875, 1.25, 1.0, 0.5, 1.0, 1.2307692307692308, 1.0, 1.0, 0.5714285714285714, 1.3, 1.0, 0.0, 1.0, 0.5, 0.0, 0.375, 1.0, 0.875, 1.1818181818181819, 1.625, 0.7272727272727273, 0.875, 0.5, 0.625, 0.6, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6363636363636364, 1.0, 1.4, 0.18181818181818182, 1.6923076923076923, 2.125, 0.875, 1.3333333333333333, 1.0, 0.5555555555555556, 1.0, 1.0, 0.125, 1.0, 0.5, 0.5714285714285714, 1.4444444444444444, 0.45454545454545453, 1.5555555555555556, 1.1428571428571428, 2.375, 1.9, 1.0, 0.5, 1.0, 1.375, 1.0, 1.0, 0.75, 0.8888888888888888, 0.6666666666666666, 0.9, 1.0, 1.0, 1.0, 0.8571428571428571, 1.5, 1.4, 1.0, 1.0, 2.0, 2.375, 1.0, 1.0, 1.0, 1.0, 1.9090909090909092, 1.0, 1.125, 1.375, 1.0, 1.0, 1.5, 0.25, 0.7777777777777778, 1.0, 1.0, 1.2222222222222223, 1.0, 0.9090909090909091, 1.0, 1.0, 1.4615384615384615, 1.0, 37.0, 1.5555555555555556, 0.8333333333333334, 1.6666666666666667, 1.0, 1.8333333333333333, 0.75, 1.0, 1.1428571428571428, 1.0, 0.7142857142857143, 1.0, 1.3, 1.5, 0.875, 2.375, 1.7, 0.75, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 4.333333333333333, 1.0, 1.0, 2.1, 1.1, 0.8, 1.0, 2.375, 1.25, 1.875, 1.2, 1.0, 1.0, 1.0, 1.0, 1.125, 2.0, 0.7, 1.0, 3.1666666666666665, 1.0, 1.25, 1.0, 2.111111111111111, 0.9, 1.0, 1.1818181818181819, 1.0, 1.1666666666666667, 1.75, 2.375, 1.0, 1.3333333333333333, 1.1666666666666667, 1.0, 1.5, 1.125, 0.875, 0.7142857142857143, 2.111111111111111, 0.8181818181818182, 0.8888888888888888, 1.8571428571428572]\n",
      "1.6306374859708195\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/DB/eval/noisy_transcribe.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.4, 2.2857142857142856, 1.0, 1.2, 1.0, 2.0, 1.0, 3.0, 0.8888888888888888, 1.0, 1.8888888888888888, 0.6923076923076923, 1.375, 2.6666666666666665, 1.2857142857142858, 66.6, 1.0, 1.0, 1.125, 0.875, 1.375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.75, 1.25, 0.4, 2.375, 1.1666666666666667, 0.375, 0.6666666666666666, 1.2222222222222223, 1.6363636363636365, 2.111111111111111, 1.0, 1.0, 0.9230769230769231, 1.0, 1.0, 1.0, 1.0, 1.0, 2.4444444444444446, 3.6666666666666665, 1.0, 1.0, 1.0, 0.7142857142857143, 2.111111111111111, 0.9090909090909091, 0.7777777777777778, 1.1428571428571428, 1.0, 1.9, 1.125, 0.0, 1.0, 1.625, 0.9090909090909091, 0.875, 1.25, 1.0, 0.5, 1.0, 1.2307692307692308, 1.0, 1.0, 0.5714285714285714, 1.3, 1.0, 0.0, 1.0, 0.5, 0.0, 0.375, 1.0, 0.875, 1.1818181818181819, 1.625, 0.7272727272727273, 0.875, 0.5, 0.625, 0.6, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6363636363636364, 1.0, 1.4, 0.18181818181818182, 1.6923076923076923, 2.125, 0.875, 1.3333333333333333, 1.0, 0.5555555555555556, 1.0, 1.0, 0.125, 1.0, 0.5, 0.5714285714285714, 1.4444444444444444, 0.45454545454545453, 1.5555555555555556, 1.1428571428571428, 2.375, 1.9, 1.0, 0.5, 1.0, 1.375, 1.0, 1.0, 0.75, 0.8888888888888888, 0.6666666666666666, 0.9, 1.0, 1.0, 1.0, 0.8571428571428571, 1.5, 1.4, 1.0, 1.0, 2.0, 2.375, 1.0, 1.0, 1.0, 1.0, 1.9090909090909092, 1.0, 1.125, 1.375, 1.0, 1.0, 1.5, 0.25, 0.7777777777777778, 1.0, 1.0, 1.2222222222222223, 1.0, 0.9090909090909091, 1.0, 1.0, 1.4615384615384615, 1.0, 37.0, 1.5555555555555556, 0.8333333333333334, 1.6666666666666667, 1.0, 1.8333333333333333, 0.75, 1.0, 1.1428571428571428, 1.0, 0.7142857142857143, 1.0, 1.3, 1.5, 0.875, 2.375, 1.7, 0.75, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 4.333333333333333, 1.0, 1.0, 2.1, 1.1, 0.8, 1.0, 2.375, 1.25, 1.875, 1.2, 1.0, 1.0, 1.0, 1.0, 1.125, 2.0, 0.7, 1.0, 3.1666666666666665, 1.0, 1.25, 1.0, 2.111111111111111, 0.9, 1.0, 1.1818181818181819, 1.0, 1.1666666666666667, 1.75, 2.375, 1.0, 1.3333333333333333, 1.1666666666666667, 1.0, 1.5, 1.125, 0.875, 0.7142857142857143, 2.111111111111111, 0.8181818181818182, 0.8888888888888888, 1.8571428571428572, 1.0, 1.0, 1.0, 0.5, 0.9, 1.0, 1.0, 1.4545454545454546, 1.0, 1.0, 3.5, 1.0, 1.0, 0.7777777777777778, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 1.0, 1.0, 1.125, 1.0, 1.0, 1.0, 1.8, 1.0, 1.0, 2.3, 0.9090909090909091, 1.0, 0.8888888888888888, 1.25, 1.0, 1.0, 2.625, 1.0, 1.0, 2.3333333333333335, 0.0, 1.0, 1.375, 0.9, 1.0, 1.0, 1.0, 1.0, 49.333333333333336, 1.0, 1.0, 1.1428571428571428, 1.1111111111111112, 1.0, 1.0, 1.0, 1.0, 26.7, 1.0, 1.0, 1.0, 1.0, 1.0, 33.15384615384615, 1.0, 1.0, 1.0, 1.3333333333333333, 1.0, 1.0, 1.125, 1.0, 1.0, 1.125, 1.375, 1.0, 1.0, 1.0, 1.0, 0.6, 3.0, 1.25, 1.0, 1.3333333333333333, 1.0, 2.0, 1.0, 1.0, 1.0, 1.2222222222222223, 1.0, 0.5555555555555556, 1.0, 1.0, 1.125, 1.0, 1.0, 1.0, 0.875, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.1, 1.0, 2.625, 1.0, 0.75, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.75, 1.125, 1.3, 1.0, 1.125, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 2.625, 1.3333333333333333, 1.2, 1.0, 1.0, 1.0, 1.0, 1.5, 1.5, 1.0, 1.0, 1.0, 1.1428571428571428, 55.5, 1.0, 1.0, 0.875, 1.0, 1.0, 1.0, 1.0, 0.875, 1.0, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.4, 2.0, 0.75, 1.0, 1.0, 1.25, 1.0, 1.0, 0.875, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.4, 1.0, 0.75, 1.0, 1.0, 1.0, 2.5, 1.0, 1.0, 1.125, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 55.5, 1.0, 1.0, 1.0, 1.4, 1.0, 0.16666666666666666, 1.0, 0.875, 1.25, 1.0, 1.0, 1.0, 0.875, 1.0, 1.0, 1.1111111111111112]\n",
      "1.8345285886952554\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/DB/output/LGHnA_v6_pre_transcribe_vad.txt\"\n",
    "\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.625, 1.0, 0.75, 2.1, 1.0, 1.0, 0.6363636363636364, 1.0, 40.36363636363637, 3.3333333333333335, 1.8888888888888888, 1.0, 1.0, 1.0, 1.0, 1.0, 49.333333333333336, 1.0, 1.6666666666666667, 1.2, 1.0, 1.125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.5, 1.0, 1.0, 1.0, 2.3333333333333335, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.2222222222222223, 0.5, 1.125, 1.0, 0.1, 1.0, 1.0, 1.0, 1.0, 1.8888888888888888, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7, 1.0, 1.0, 1.0, 1.0, 2.3333333333333335, 0.625, 1.0, 1.0, 1.0, 1.0, 1.0, 1.125, 1.0, 0.75, 1.0, 2.3333333333333335, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 0.9, 1.0, 1.0, 0.8888888888888888, 1.0, 1.0, 1.0, 1.0909090909090908, 1.0, 1.0, 2.0, 1.125, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.1111111111111112, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 29.6, 1.0, 1.0, 1.2222222222222223, 1.4545454545454546, 1.0, 2.0, 1.0, 1.0, 1.0, 0.875, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7142857142857143, 1.0, 1.2, 1.0, 1.0, 0.875, 1.0, 1.0, 1.125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.2, 2.0, 1.0, 1.1, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.5, 2.625, 1.5714285714285714, 1.5714285714285714, 1.0, 1.0, 1.0, 1.0, 1.0, 1.5, 1.0, 1.3333333333333333, 53.875, 1.0, 1.0, 1.0, 0.3, 1.0, 1.0, 1.0, 1.125, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 38.0, 1.0, 0.875, 1.0, 1.0, 1.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.1111111111111112, 1.0, 1.3333333333333333, 1.0, 1.0, 1.0, 1.1, 1.5, 1.0, 74.0, 1.375, 1.0, 1.4, 1.2222222222222223, 0.5, 1.0, 1.0, 2.625, 1.0, 1.0, 1.375, 1.0, 1.0, 1.0, 1.0]\n",
      "2.3318880872214205\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/inference/WF/MappingNet_default_pre_transcribe_vad.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9, 1.875, 1.1, 0.375, 2.1, 1.1818181818181819, 1.0, 0.7272727272727273, 2.3333333333333335, 1.0909090909090908, 1.0, 49.333333333333336, 1.5454545454545454, 0.6666666666666666, 2.625, 0.0, 0.8888888888888888, 0.8888888888888888, 0.7, 1.0, 0.2, 1.0, 1.0, 1.1666666666666667, 1.5, 0.75, 1.6, 1.0, 1.0, 2.3, 1.0, 0.25, 2.3333333333333335, 1.125, 1.25, 1.0, 2.625, 1.0, 1.0, 1.0, 0.3333333333333333, 2.125, 1.0, 0.2, 0.7142857142857143, 1.0, 1.0, 1.0, 0.6666666666666666, 0.875, 1.0, 1.0, 1.4444444444444444, 1.6153846153846154, 1.0, 2.5, 0.8, 0.9, 0.8, 1.1428571428571428, 1.4, 1.0, 0.625, 1.0, 2.111111111111111, 0.6666666666666666, 1.25, 1.8333333333333333, 1.25, 1.1666666666666667, 0.75, 1.0, 1.4444444444444444, 0.5, 1.125, 0.9230769230769231, 1.0, 1.0, 2.5, 0.4, 1.0, 1.0, 1.0, 1.1666666666666667, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 2.0, 2.5, 1.1111111111111112, 1.25, 1.0, 0.375, 2.0, 1.0, 1.0, 0.625, 1.0, 1.0, 1.5454545454545454, 1.0, 0.9, 1.0, 1.0, 1.625, 1.2, 1.0, 1.625, 1.0, 1.0, 1.0, 1.0, 1.4545454545454546, 2.625, 1.0, 0.75, 0.0, 2.375, 0.3333333333333333, 1.0, 1.125, 1.0, 1.0, 1.0, 0.5, 0.7272727272727273, 0.7142857142857143, 0.75, 1.2, 1.0, 0.16666666666666666, 0.5, 2.0, 1.0, 1.0, 1.0, 1.0, 1.6153846153846154, 1.2307692307692308, 1.0, 0.375, 1.0, 1.0, 1.75, 0.8888888888888888, 0.6, 0.45454545454545453, 1.125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.2857142857142856, 0.42857142857142855, 0.75, 1.0, 1.0, 2.625, 0.625, 0.6666666666666666, 0.75, 0.6666666666666666, 2.625, 1.0, 0.5, 1.1428571428571428, 0.3, 1.125, 1.2, 1.0, 1.0, 1.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.25, 2.3, 2.3333333333333335, 0.5, 1.0, 1.0, 1.0, 0.7, 1.0, 1.0, 1.0, 0.9, 1.0, 1.0, 0.8461538461538461, 3.875, 1.125, 2.5, 3.5, 1.0, 2.0, 1.0, 0.8571428571428571, 1.625, 0.875, 1.0, 1.0, 1.125, 2.6666666666666665, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.4545454545454546, 1.0, 0.625, 0.16666666666666666, 1.0, 1.0]\n",
      "1.340614225280892\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/inference/BF/MappingNet_default_pre_transcribe_vad.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 0.625, 0.9, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.3333333333333333, 2.3333333333333335, 1.3333333333333333, 0.9, 1.0, 1.0, 2.1, 1.125, 1.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.25, 1.0, 1.375, 1.0, 1.0, 1.0, 1.0, 1.75, 1.2222222222222223, 0.0, 1.375, 1.375, 0.4, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.75, 1.8, 1.0, 2.0, 1.0, 1.0, 55.5, 1.4, 0.9, 1.0, 1.0, 1.2, 37.0, 1.0, 1.0, 2.3333333333333335, 1.0, 1.0, 1.3333333333333333, 0.75, 1.0, 0.75, 1.0, 1.0, 1.125, 0.875, 0.9230769230769231, 1.0, 1.0, 1.0, 0.7, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.9, 1.0, 1.0, 1.0, 0.8888888888888888, 1.125, 1.2857142857142858, 1.0, 1.0, 1.9090909090909092, 1.0, 1.25, 1.1428571428571428, 1.0, 1.0, 1.1111111111111112, 1.0, 1.0, 1.0, 1.0, 22.2, 1.0, 1.0, 2.3333333333333335, 1.0909090909090908, 1.0, 1.0, 1.0909090909090908, 1.0, 1.0, 1.0, 0.6, 1.0, 0.8333333333333334, 1.0, 1.125, 1.0, 1.0, 1.125, 1.0, 1.0, 0.7142857142857143, 1.0, 1.0, 1.0, 0.8333333333333334, 0.875, 1.0, 1.0, 1.0, 1.0, 1.0, 1.6153846153846154, 1.0, 1.0, 0.75, 1.0, 1.0, 2.625, 1.0, 1.1, 1.0909090909090908, 1.0, 1.0, 1.0, 0.875, 1.375, 1.0, 1.0, 62.0, 1.5714285714285714, 1.125, 1.0, 1.0, 2.625, 1.875, 1.3333333333333333, 1.0, 1.0, 0.875, 1.0, 0.5, 1.0, 0.6, 1.0, 1.1, 1.0, 1.375, 1.0, 1.0, 3.0, 1.0, 0.9090909090909091, 40.36363636363637, 1.0, 1.0, 1.0, 1.0, 1.0, 50.375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.4, 1.0, 0.875, 1.1538461538461537, 1.0, 1.0, 0.875, 1.0, 1.0, 2.625, 1.0, 1.0, 0.75, 1.0, 0.9, 1.0, 1.875, 1.0, 53.5, 1.0, 1.1, 1.1111111111111112, 0.5, 1.0, 0.875, 1.0, 1.0, 1.0, 1.0, 0.875, 1.0, 1.0, 1.1111111111111112]\n",
      "2.4770666617333283\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/DB/output/MappingNet_default_pre_transcribe_vad.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7142857142857143, 0.4444444444444444, 1.25, 0.0, 1.125, 0.5, 0.5, 1.3636363636363635, 0.25, 0.0, 0.0, 0.8333333333333334, 1.0, 0.625, 0.0, 0.75, 0.16666666666666666, 0.375, 1.1, 1.0, 0.6923076923076923, 0.3333333333333333, 0.4, 0.0, 0.5, 0.7, 0.75, 0.0, 0.7777777777777778, 0.18181818181818182, 0.6666666666666666, 0.42857142857142855, 0.3333333333333333, 0.1, 0.0, 0.0, 0.75, 0.5, 0.7, 0.125, 0.0, 1.0769230769230769, 1.0, 1.0, 0.875, 0.5454545454545454, 0.0, 0.5, 1.0, 0.3333333333333333, 0.0, 0.125, 0.0, 1.4, 1.75, 0.375, 0.75, 0.375, 0.7272727272727273, 1.125, 0.5454545454545454, 1.375, 0.375, 0.5, 0.375, 0.0, 1.0, 0.75, 0.0, 0.75, 0.4, 0.375, 0.375, 0.18181818181818182, 0.5, 1.0, 0.0, 0.75, 0.5, 0.6363636363636364, 0.09090909090909091, 0.875, 0.0, 0.375, 0.875, 0.2727272727272727, 0.0, 0.0, 1.125, 0.6363636363636364, 0.0, 1.0, 1.25, 1.1818181818181819, 0.5, 1.7142857142857142, 0.0, 0.8333333333333334, 0.5, 0.45454545454545453, 0.7, 0.3333333333333333, 1.25, 0.5714285714285714, 1.4285714285714286, 0.25, 0.2222222222222222, 0.4444444444444444, 0.7142857142857143, 0.3333333333333333, 1.0, 0.18181818181818182, 0.0, 0.6666666666666666, 1.25, 0.375, 0.9, 0.6666666666666666, 1.4285714285714286, 0.0, 0.0, 1.1666666666666667, 0.7, 0.6, 1.125, 1.4, 0.46153846153846156, 0.0, 0.6666666666666666, 1.5, 1.0, 0.6923076923076923, 0.0, 0.6666666666666666, 0.5, 0.6363636363636364, 0.2, 0.6666666666666666, 0.8888888888888888, 0.25, 0.875, 0.5, 0.0, 0.5, 0.3333333333333333, 0.5, 1.3333333333333333, 0.2857142857142857, 0.75, 0.0, 0.0, 1.75, 0.0, 0.0, 0.375, 1.0, 2.0, 0.8888888888888888, 0.1, 1.5714285714285714, 0.375, 0.5384615384615384, 0.1, 0.0, 0.875, 1.1, 1.0, 0.8571428571428571, 0.6666666666666666, 1.1818181818181819, 0.75, 0.5, 1.3333333333333333, 0.625, 1.0, 0.75, 0.375, 0.6363636363636364, 0.6666666666666666, 0.5454545454545454, 0.3, 0.16666666666666666, 0.5, 0.25, 0.0, 0.0, 1.125, 1.0, 0.42857142857142855, 0.0, 0.2222222222222222, 0.5, 0.5454545454545454, 0.7, 0.6666666666666666, 0.2727272727272727, 0.6666666666666666, 0.0, 0.375, 0.5833333333333334, 0.0, 0.0, 1.0909090909090908, 1.0, 0.15384615384615385, 1.25, 0.5, 0.18181818181818182, 1.1428571428571428, 0.5, 0.375, 0.1111111111111111, 0.5555555555555556, 0.7777777777777778, 0.8888888888888888, 1.375, 0.5454545454545454, 0.2222222222222222, 0.25, 0.42857142857142855, 0.0, 0.1, 1.25, 1.0, 0.25]\n",
      "0.5764169410836077\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/transcribe/d2_AEC.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.2857142857142857, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111, 0.0, 0.1111111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.1, 0.0, 0.0, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1111111111111111, 0.14285714285714285, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0]\n",
      "0.012113516113516114\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/transcribe/d3_clean.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.9, 1.0, 55.5, 1.0, 1.0, 1.0, 1.125, 1.125, 1.0, 1.0, 1.0, 1.2307692307692308, 1.0, 2.1666666666666665, 2.2857142857142856, 1.0, 1.0, 1.0, 1.0, 2.125, 1.0, 1.0, 1.125, 1.0, 2.1818181818181817, 1.0, 1.125, 1.0, 1.0, 1.0, 1.0, 1.5, 1.0, 4.0, 1.0, 1.0, 1.5555555555555556, 1.0, 1.0, 1.0, 0.9166666666666666, 1.125, 1.5, 1.0, 3.6666666666666665, 1.0, 2.8333333333333335, 1.0, 1.125, 2.75, 0.8571428571428571, 0.8888888888888888, 0.9090909090909091, 1.0, 3.4285714285714284, 1.0, 0.9, 3.0, 1.0, 1.0, 1.625, 1.2727272727272727, 1.5, 1.125, 1.0, 1.0, 2.111111111111111, 1.0, 2.25, 1.5, 1.2857142857142858, 1.0, 1.0, 1.0, 1.125, 1.125, 1.9, 1.25, 1.0, 1.0, 1.0909090909090908, 1.0, 1.0, 2.0, 1.25, 1.125, 1.0, 1.0, 2.6666666666666665, 1.375, 1.1111111111111112, 40.36363636363637, 1.0, 1.0, 1.8181818181818181, 1.0, 1.75, 2.25, 0.9166666666666666, 1.0, 1.0, 1.0, 2.6666666666666665, 2.75, 1.0, 1.5, 1.2857142857142858, 0.8888888888888888, 0.9090909090909091, 1.0, 1.0, 1.125, 1.5, 55.5, 1.0, 1.3, 1.125, 1.0, 1.125, 2.125, 1.0, 1.8888888888888888, 1.8, 1.0, 2.0, 1.5, 1.0, 1.0, 1.0, 1.0, 48.5, 1.0, 1.75, 1.0, 1.0, 1.1818181818181819, 1.125, 1.4545454545454546, 2.375, 1.0, 1.0, 1.0, 1.125, 1.5, 1.125, 0.8888888888888888, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.125, 1.0, 1.875, 1.5, 1.8888888888888888, 1.5, 1.0, 2.0, 1.5, 1.0, 1.0, 1.2857142857142858, 0.9090909090909091, 3.0, 1.0, 1.0, 1.125, 1.0, 1.125, 1.6, 2.0, 1.0, 2.0, 2.0, 1.125, 2.5555555555555554, 1.0, 2.2222222222222223, 1.0, 1.5, 1.125, 1.0, 1.3, 1.0, 1.0, 1.0, 1.125, 1.0, 1.125, 1.0, 1.125, 1.0, 1.0, 1.125, 1.125, 3.0, 1.0, 2.125, 1.0, 2.6666666666666665, 1.125, 1.0, 1.0, 1.3, 1.0, 1.0, 1.0, 0.9166666666666666, 1.125, 2.0, 1.0, 1.0, 1.5, 1.5, 3.1666666666666665, 2.0, 2.25, 1.0, 1.0, 1.4545454545454546, 1.0, 1.2857142857142858]\n",
      "2.1953281903281905\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/transcribe/d3_noisy.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.375, 1.0, 1.7142857142857142, 1.0, 0.9, 1.0, 1.0, 1.125, 1.0, 2.111111111111111, 1.1, 0.7777777777777778, 1.6923076923076923, 1.125, 1.3333333333333333, 1.0, 1.2, 0.5, 1.0, 0.0, 1.5, 1.375, 44.4, 1.125, 1.25, 1.3636363636363635, 1.0, 1.0, 1.0, 1.0, 0.6, 0.875, 2.6666666666666665, 1.625, 1.1666666666666667, 1.6666666666666667, 1.0909090909090908, 1.1111111111111112, 1.0, 1.0, 1.0769230769230769, 1.25, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.5, 0.6666666666666666, 1.0, 1.0, 0.7142857142857143, 1.4444444444444444, 0.9090909090909091, 1.0, 1.0, 0.5, 1.0, 1.0, 0.75, 0.5, 1.0, 0.9090909090909091, 1.0, 0.625, 1.3333333333333333, 1.0, 1.0, 0.6153846153846154, 1.75, 1.0, 1.0, 1.2, 0.6, 1.2, 1.0, 0.25, 1.7, 0.875, 0.625, 1.125, 1.3636363636363635, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.1666666666666667, 0.75, 0.3333333333333333, 1.0, 1.0, 1.7, 1.0, 0.7692307692307693, 1.25, 0.0, 0.8333333333333334, 0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.25, 1.375, 1.0, 1.4285714285714286, 1.2222222222222223, 0.8181818181818182, 2.0, 1.1428571428571428, 1.0, 0.9, 1.125, 1.25, 1.0, 1.0, 1.0, 1.0, 1.25, 1.0, 1.3333333333333333, 2.8, 1.0, 1.0, 1.0, 1.1428571428571428, 66.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.1, 1.0, 1.3636363636363635, 55.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.375, 1.0, 2.375, 1.0, 2.5, 1.0, 1.0, 1.0, 1.1818181818181819, 1.25, 1.0, 1.0769230769230769, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.5, 1.0, 1.1428571428571428, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.125, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 49.333333333333336, 1.0, 1.0, 1.2307692307692308, 2.3333333333333335, 2.125, 2.0, 0.7, 1.5, 1.0, 1.0, 1.0, 0.75, 1.125, 1.0, 1.0, 1.3636363636363635, 1.0, 1.0, 1.125, 1.5, 1.3, 1.125, 1.0, 1.3333333333333333, 1.5, 1.0, 1.0, 1.3, 1.0, 0.9090909090909091, 1.0, 1.0, 0.875, 0.875, 0.8333333333333334, 1.0, 1.1666666666666667, 1.0, 1.1666666666666667, 0.875, 1.0, 2.7142857142857144, 1.8888888888888888, 1.0, 0.8888888888888888, 1.0]\n",
      "2.0170852727519395\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/transcribe/d3_AEC.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.125, 0.0, 0.2857142857142857, 0.0, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.14285714285714285, 0.0, 0.0, 0.1111111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.375, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0]\n",
      "0.01715616482283149\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/transcribe/t0_clean.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.9, 2.2857142857142856, 1.125, 1.0, 1.0, 1.4545454545454546, 1.0, 1.0, 1.0, 1.2, 1.7777777777777777, 1.0, 1.125, 3.1666666666666665, 1.0, 2.1, 1.6, 1.0, 1.5, 1.875, 1.25, 1.1, 92.0, 2.25, 0.9090909090909091, 1.0, 1.625, 1.0, 1.0, 1.1, 0.5, 1.3333333333333333, 1.125, 1.0, 1.5555555555555556, 1.0, 1.0, 1.0, 1.2727272727272727, 0.9230769230769231, 1.0, 2.125, 1.6666666666666667, 1.625, 4.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 63.42857142857143, 1.8888888888888888, 0.9090909090909091, 0.8888888888888888, 1.0, 1.125, 0.5, 1.0, 0.0, 0.9, 0.5, 1.0, 1.0, 0.5, 1.0, 0.6, 1.2222222222222223, 1.3846153846153846, 2.375, 1.6666666666666667, 0.2857142857142857, 1.2, 0.0, 0.9, 2.625, 0.0, 0.0, 0.375, 0.125, 1.0, 0.45454545454545453, 0.875, 1.2727272727272727, 0.875, 0.875, 0.25, 0.6, 0.8333333333333334, 1.0, 2.75, 1.1111111111111112, 1.4545454545454546, 1.3333333333333333, 0.9, 0.8181818181818182, 1.0, 0.875, 1.0, 1.1666666666666667, 1.0, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 1.0, 1.0, 0.8333333333333334, 1.0, 0.4444444444444444, 1.0, 1.0, 0.8571428571428571, 1.0, 1.2, 1.75, 1.625, 1.2, 1.25, 1.0, 2.0, 0.625, 0.6666666666666666, 1.1111111111111112, 0.8, 0.9230769230769231, 1.0, 74.0, 1.0, 1.0, 1.2, 0.4, 1.0, 2.375, 2.25, 1.4, 3.0, 1.2727272727272727, 1.0, 1.0, 1.0, 1.25, 0.5, 1.1, 0.375, 1.3333333333333333, 1.0, 0.8888888888888888, 0.8333333333333334, 1.4545454545454546, 1.5555555555555556, 1.1, 1.2727272727272727, 1.0, 0.75, 1.4615384615384615, 0.75, 1.0, 0.8888888888888888, 1.0, 0.8333333333333334, 1.0, 1.0, 0.75, 1.0, 1.1428571428571428, 1.0, 1.0, 1.2222222222222223, 1.1, 2.0, 1.0, 1.125, 1.4, 0.75, 1.0, 1.0, 1.25, 1.875, 1.0, 1.0, 0.7777777777777778, 1.0, 1.0, 1.125, 1.7142857142857142, 1.0, 1.0, 2.3, 1.0, 1.25, 2.25, 1.25, 1.0, 0.875, 1.5454545454545454, 1.0, 1.125, 55.375, 1.0, 1.1, 1.0, 1.0, 1.1666666666666667, 1.0, 1.0, 0.8888888888888888, 1.3, 1.0, 0.9090909090909091, 1.0, 0.9166666666666666, 1.0, 2.125, 2.1666666666666665, 1.0, 0.6666666666666666, 1.0, 1.0, 1.625, 2.75, 0.42857142857142855, 1.4444444444444444, 1.0, 1.1111111111111112, 1.1428571428571428]\n",
      "2.379803554470221\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/transcribe/t0_noisy.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.125, 0.2, 1.1428571428571428, 1.0, 1.5, 0.875, 0.6363636363636364, 1.125, 0.75, 0.0, 0.9, 1.4444444444444444, 0.46153846153846156, 1.75, 2.6666666666666665, 0.5714285714285714, 1.3, 0.9, 1.1, 1.0, 0.625, 0.625, 0.6, 1.125, 1.5, 0.5454545454545454, 0.8181818181818182, 1.125, 0.875, 0.125, 0.8, 0.5, 1.8333333333333333, 0.5, 1.0, 1.2222222222222223, 1.0909090909090908, 0.6666666666666666, 0.8, 0.9090909090909091, 1.0, 0.8333333333333334, 0.5, 1.1666666666666667, 0.875, 0.5, 0.2222222222222222, 1.3333333333333333, 0.3333333333333333, 0.25, 0.5, 0.7142857142857143, 1.1111111111111112, 0.6363636363636364, 1.1111111111111112, 0.14285714285714285, 0.0, 0.1, 0.75, 0.0, 0.0, 1.0, 0.18181818181818182, 0.125, 0.25, 0.2222222222222222, 0.5, 0.0, 0.0, 1.125, 0.3333333333333333, 0.2857142857142857, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.75, 0.18181818181818182, 0.25, 0.45454545454545453, 0.5, 0.25, 0.625, 0.1, 1.1666666666666667, 0.0, 0.5, 0.0, 0.45454545454545453, 0.4444444444444444, 0.2, 0.2727272727272727, 1.0, 0.25, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.3333333333333333, 0.25, 1.0, 0.0, 0.5714285714285714, 0.3333333333333333, 0.2727272727272727, 0.2222222222222222, 0.0, 1.25, 0.1, 1.125, 0.625, 1.3, 0.375, 1.7272727272727273, 1.375, 1.25, 0.5555555555555556, 1.4444444444444444, 1.3, 0.7692307692307693, 0.625, 1.6666666666666667, 1.0, 0.7, 1.1, 0.6, 0.5, 1.0, 1.75, 0.2, 1.25, 1.0, 1.125, 32.36363636363637, 0.875, 1.125, 0.375, 0.8, 0.25, 0.6666666666666666, 0.5, 1.2222222222222223, 0.3333333333333333, 0.6363636363636364, 1.2222222222222223, 0.6, 0.8181818181818182, 0.8333333333333334, 1.125, 0.9230769230769231, 0.0, 0.5, 0.4444444444444444, 0.8333333333333334, 0.6666666666666666, 1.5, 0.8333333333333334, 0.875, 0.7777777777777778, 0.8571428571428571, 0.7272727272727273, 1.0, 1.0, 1.0, 1.5, 0.625, 1.0, 1.2, 1.0, 1.2727272727272727, 0.625, 1.625, 1.0, 1.2222222222222223, 1.0, 0.8888888888888888, 0.9230769230769231, 1.0, 0.75, 0.5714285714285714, 1.1, 0.6, 1.1, 1.0, 1.0, 0.375, 1.0, 1.1, 0.625, 1.0909090909090908, 1.3636363636363635, 1.5, 0.875, 0.375, 0.8, 0.875, 1.0, 1.5, 1.125, 0.6666666666666666, 0.0, 1.0, 1.1818181818181819, 0.6363636363636364, 1.0, 0.6666666666666666, 0.625, 1.0, 0.5, 0.8888888888888888, 0.6666666666666666, 1.1666666666666667, 0.16666666666666666, 1.0, 0.5, 0.7142857142857143, 0.5555555555555556, 0.8181818181818182, 0.3333333333333333, 1.4285714285714286]\n",
      "0.8781039454372788\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/transcribe/t0_AEC.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.125, 1.6, 1.0, 1.0, 1.0, 2.375, 1.0, 1.375, 1.0, 1.0, 1.0, 2.111111111111111, 1.0769230769230769, 1.0, 1.0, 1.2857142857142858, 1.0, 1.7, 1.4, 1.25, 1.625, 1.125, 1.4, 3.0, 1.125, 1.0, 1.0, 1.0, 2.75, 1.0, 1.0, 1.0, 1.5, 1.125, 1.3333333333333333, 2.111111111111111, 1.7272727272727273, 1.1111111111111112, 1.0, 1.0, 0.9230769230769231, 1.0, 1.5, 1.1666666666666667, 2.375, 2.5, 1.0, 3.6666666666666665, 1.0, 2.25, 1.375, 1.0, 1.0, 0.8181818181818182, 1.3333333333333333, 1.0, 2.0, 1.0, 2.25, 1.0, 1.0, 1.25, 1.4545454545454546, 1.0, 0.75, 1.0, 0.8, 1.1111111111111112, 0.9230769230769231, 1.0, 1.5, 1.0, 2.3, 1.0, 0.7, 1.5, 1.375, 1.0, 0.625, 1.0, 1.0, 1.0909090909090908, 1.0, 1.6363636363636365, 1.125, 0.5, 1.125, 1.0, 1.0, 2.0, 1.125, 0.8888888888888888, 0.9090909090909091, 1.0, 1.0, 1.0, 1.0, 1.25, 1.0, 1.4166666666666667, 1.0, 1.0, 0.8333333333333334, 1.0, 0.625, 0.875, 2.1666666666666665, 0.8571428571428571, 1.1111111111111112, 1.1818181818181819, 1.0, 1.0, 1.0, 0.9, 1.0, 1.0, 1.7, 1.0, 1.0, 1.0, 1.625, 1.0, 1.5555555555555556, 1.0, 1.0, 2.625, 1.0, 1.0, 1.2, 1.0, 1.0, 0.625, 1.625, 2.25, 1.7, 2.375, 1.8181818181818181, 1.0, 1.1818181818181819, 1.0, 1.0, 1.0, 1.6, 1.0, 1.0, 2.375, 1.7777777777777777, 1.1666666666666667, 1.1818181818181819, 1.6666666666666667, 1.4, 0.9090909090909091, 1.0, 1.0, 1.6923076923076923, 1.75, 1.3333333333333333, 2.111111111111111, 0.16666666666666666, 3.0, 2.375, 1.0, 2.125, 1.7777777777777777, 0.8571428571428571, 0.9090909090909091, 1.4285714285714286, 0.8888888888888888, 1.0, 1.125, 1.375, 74.0, 1.6, 1.125, 63.72727272727273, 1.0, 1.125, 1.0, 1.2222222222222223, 1.0, 1.4444444444444444, 1.0, 1.0, 1.0, 1.0, 1.0, 1.4, 1.6, 1.625, 1.25, 1.0, 1.125, 1.4, 1.0, 1.0, 1.7272727272727273, 1.125, 1.5, 1.375, 1.6, 1.0, 2.1666666666666665, 1.8333333333333333, 1.0, 1.2222222222222223, 1.8888888888888888, 1.0, 0.9090909090909091, 1.0, 1.4615384615384615, 1.9166666666666667, 0.75, 1.0, 2.6666666666666665, 1.0, 2.1666666666666665, 1.5, 4.0, 1.0, 1.0, 0.8571428571428571, 1.1111111111111112, 0.9090909090909091, 1.0, 1.2857142857142858]\n",
      "1.8985942452609121\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/transcribe/t5_noisy.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.3, 1.4285714285714286, 1.0, 1.0, 1.5, 0.8181818181818182, 1.25, 0.25, 1.1111111111111112, 1.0, 1.8888888888888888, 1.4615384615384615, 1.75, 1.1666666666666667, 2.7142857142857144, 1.4, 2.1, 1.0, 1.0, 1.0, 1.125, 1.6, 1.0, 1.5, 1.0, 1.2727272727272727, 0.75, 1.625, 0.875, 0.7, 1.25, 0.6666666666666666, 1.375, 1.0, 1.5555555555555556, 1.4545454545454546, 1.3333333333333333, 1.3, 1.0, 1.0, 1.0, 1.25, 1.0, 0.375, 0.8333333333333334, 0.6666666666666666, 1.0, 0.5, 1.375, 0.875, 1.1428571428571428, 0.6666666666666666, 0.7272727272727273, 1.2222222222222223, 1.0, 0.25, 0.2, 0.75, 0.25, 0.4, 0.5, 0.7272727272727273, 0.375, 0.375, 0.5555555555555556, 0.6, 1.1111111111111112, 0.6153846153846154, 1.0, 1.0, 0.5714285714285714, 1.1, 1.0, 0.4, 1.0, 0.125, 0.9, 0.5, 0.75, 1.125, 0.36363636363636365, 0.125, 1.9090909090909092, 0.875, 0.625, 0.25, 0.7, 1.3333333333333333, 1.0, 1.0, 1.1111111111111112, 0.9090909090909091, 0.6666666666666666, 0.2, 0.8181818181818182, 1.3076923076923077, 0.375, 0.5, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.875, 1.0, 0.8333333333333334, 0.2857142857142857, 0.4444444444444444, 1.0, 0.7777777777777778, 1.0, 1.5, 0.6, 1.625, 0.75, 1.3, 1.0, 0.9090909090909091, 1.0, 1.0, 1.1111111111111112, 1.4444444444444444, 0.9, 1.0, 1.0, 1.1666666666666667, 1.0, 0.9, 1.0, 1.0, 1.0, 0.875, 1.375, 1.1, 1.25, 1.0, 1.0, 1.0, 1.0, 0.875, 0.625, 1.0, 1.0, 0.8333333333333334, 1.125, 1.0, 1.0, 1.0, 1.3333333333333333, 0.9, 1.1818181818181819, 1.0, 1.5, 1.6153846153846154, 0.875, 0.16666666666666666, 1.3333333333333333, 1.3333333333333333, 0.6666666666666666, 2.375, 0.3333333333333333, 1.0, 1.2222222222222223, 0.7142857142857143, 1.4545454545454546, 1.0, 0.6666666666666666, 0.6, 1.0, 1.0, 1.625, 1.6, 1.0, 0.9090909090909091, 1.125, 1.0, 1.125, 1.0, 1.3, 0.8888888888888888, 0.9230769230769231, 1.0, 1.125, 1.0, 1.0, 0.9, 1.4, 1.0, 1.75, 1.125, 1.0, 0.6, 1.5, 1.6363636363636365, 1.0909090909090908, 1.5, 1.125, 0.5, 1.0, 1.25, 1.8333333333333333, 1.1666666666666667, 1.0, 1.0, 1.2222222222222223, 1.0, 1.7272727272727273, 1.5454545454545454, 1.3076923076923077, 1.0833333333333333, 1.125, 1.375, 1.1666666666666667, 1.1111111111111112, 0.5, 0.8333333333333334, 1.0, 0.75, 1.0, 0.7142857142857143, 1.1111111111111112, 1.0, 0.8888888888888888, 1.2857142857142858]\n",
      "0.99660845327512\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/transcribe/t5_AEC.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.9, 2.7142857142857144, 1.0, 1.0, 1.0, 2.1818181818181817, 3.0, 3.0, 1.0, 1.8, 1.0, 1.2307692307692308, 3.0, 3.1666666666666665, 1.2857142857142858, 1.0, 1.1, 0.8, 1.0, 2.375, 1.0, 1.0, 1.125, 1.125, 1.4545454545454546, 1.0909090909090908, 1.0, 2.0, 1.0, 2.4, 1.0, 1.0, 1.25, 3.1666666666666665, 1.0, 1.0, 1.0, 1.7, 2.1818181818181817, 1.0769230769230769, 0.9166666666666666, 1.125, 0.8333333333333334, 2.375, 1.0, 79.44444444444444, 3.8333333333333335, 1.0, 1.0, 3.25, 1.0, 2.0, 1.0, 1.2222222222222223, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.7272727272727273, 1.0, 1.125, 1.0, 2.5, 1.8888888888888888, 1.0, 1.0, 2.6666666666666665, 2.5714285714285716, 1.8, 1.0, 1.9, 1.125, 1.0, 1.0, 1.125, 1.0, 1.0, 1.0, 1.125, 1.4545454545454546, 2.0, 1.0, 1.0, 1.0, 1.5, 1.3333333333333333, 1.0, 73.0, 1.0, 1.6666666666666667, 1.0, 1.5454545454545454, 1.4615384615384615, 2.375, 1.5, 1.0, 1.0, 2.3333333333333335, 113.83333333333333, 3.0, 2.75, 1.875, 0.6666666666666666, 1.4285714285714286, 1.6666666666666667, 0.9090909090909091, 1.0, 1.0, 1.125, 0.9, 1.0, 2.625, 1.7, 1.0, 1.7272727272727273, 1.25, 81.25, 1.0, 1.0, 1.5, 1.4615384615384615, 1.25, 1.0, 0.8571428571428571, 1.0, 67.5, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.7272727272727273, 1.125, 1.0, 1.0, 1.0, 1.5, 1.0, 1.0, 1.5, 42.375, 1.0, 1.0, 1.0, 2.5555555555555554, 1.4, 65.27272727272727, 0.9166666666666666, 2.125, 1.0, 1.0, 2.5, 1.4444444444444444, 1.0, 1.0, 2.25, 1.0, 2.375, 1.0, 2.0, 1.0909090909090908, 1.2857142857142858, 1.8888888888888888, 2.4, 2.0, 1.875, 1.0, 1.0, 2.125, 1.0, 2.375, 1.125, 2.0, 2.5555555555555554, 1.7, 1.0, 1.0769230769230769, 1.0, 1.0, 2.4285714285714284, 1.0, 1.4, 1.4, 1.625, 1.0, 1.25, 2.0, 1.0, 2.375, 1.0, 1.0, 2.375, 1.0, 0.875, 1.0, 1.5, 4.166666666666667, 1.0, 1.125, 1.8888888888888888, 1.8888888888888888, 1.0, 2.1818181818181817, 39.45454545454545, 1.0, 1.5, 1.0, 1.0, 3.1666666666666665, 1.0, 2.1666666666666665, 1.0, 2.5, 1.75, 1.125, 1.2857142857142858, 1.8888888888888888, 1.0, 1.1111111111111112, 1.1428571428571428]\n",
      "3.9078243114909785\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/transcribe/t10_noisy.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 1.3, 1.0, 1.0, 1.0, 1.0, 1.0, 1.875, 1.0, 1.3333333333333333, 1.0, 1.7777777777777777, 1.0, 1.0, 1.0, 2.7142857142857144, 1.0, 1.0, 1.7, 1.0, 1.5, 1.5, 1.0, 1.0, 1.0, 1.0, 1.5454545454545454, 160.25, 1.25, 1.0, 1.1, 160.25, 1.0, 2.125, 1.0, 1.0, 1.7272727272727273, 1.0, 1.5, 1.5454545454545454, 1.0, 1.4166666666666667, 1.0, 1.0, 1.0, 1.0, 0.8888888888888888, 1.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.3, 1.5, 1.0, 1.4, 1.125, 1.4545454545454546, 0.875, 0.875, 1.4444444444444444, 1.0, 1.2222222222222223, 1.0, 1.0, 2.0, 3.142857142857143, 1.2, 1.0, 1.4, 1.25, 2.125, 1.2, 1.0, 1.125, 1.125, 0.9090909090909091, 0.875, 1.3636363636363635, 1.5, 2.125, 1.0, 44.4, 2.8333333333333335, 1.3333333333333333, 0.875, 72.0, 40.45454545454545, 1.0, 0.5, 0.9090909090909091, 1.0769230769230769, 0.875, 0.375, 1.0, 0.8333333333333334, 0.4444444444444444, 1.1666666666666667, 1.0, 0.875, 43.125, 0.8333333333333334, 1.0, 1.0, 0.6363636363636364, 1.1111111111111112, 1.0, 1.0, 1.0, 1.625, 1.5, 1.4, 1.0, 1.1818181818181819, 1.0, 1.0, 1.3333333333333333, 1.0, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.875, 1.5, 1.0, 1.25, 1.0, 1.0, 1.0, 1.0, 1.375, 0.875, 1.0, 1.0, 1.0, 1.0, 1.0, 2.8333333333333335, 1.9090909090909092, 0.8888888888888888, 1.5, 1.0, 1.0833333333333333, 1.125, 1.0, 1.125, 1.0, 1.0, 0.3333333333333333, 1.0, 2.125, 1.0, 1.625, 2.4444444444444446, 1.5714285714285714, 1.3636363636363635, 1.0, 1.0, 1.0, 1.0, 1.0, 1.75, 1.5, 1.375, 1.0, 1.0, 1.875, 1.0, 1.2222222222222223, 0.7, 1.0, 1.0, 1.0, 49.0, 1.2857142857142858, 1.3, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 70.5, 1.0, 1.0, 1.3636363636363635, 1.0, 1.375, 1.0, 1.0, 126.125, 1.0, 1.0, 1.375, 0.4444444444444444, 1.0, 1.2, 1.0, 1.0, 1.0, 1.4166666666666667, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.5, 1.0, 2.5714285714285716, 1.0, 1.2727272727272727, 1.0, 0.8571428571428571]\n",
      "4.528496441829775\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/transcribe/t10_AEC.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.125, 0.9, 2.0, 1.0, 1.0, 1.0, 1.0, 2.375, 1.0, 1.3333333333333333, 1.4, 2.6666666666666665, 1.0, 1.75, 1.0, 1.0, 1.0, 1.0, 2.3, 3.0, 1.0, 1.125, 1.2, 1.0, 1.5, 1.2727272727272727, 1.0, 2.125, 1.0, 1.0, 2.4, 1.0, 74.0, 1.0, 1.0, 1.3333333333333333, 1.0, 1.0, 1.0, 65.63636363636364, 1.0, 0.9166666666666666, 1.125, 74.0, 1.0, 1.0, 1.0, 3.0, 1.5, 1.0, 1.125, 1.0, 1.0, 1.4545454545454546, 1.0, 3.4285714285714284, 2.125, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.375, 1.125, 1.7777777777777777, 1.0, 1.7777777777777777, 1.2307692307692308, 1.125, 4.0, 1.2857142857142858, 1.0, 1.0, 1.0, 1.0, 1.5, 1.0, 1.25, 1.125, 1.125, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.3846153846153846, 3.0, 1.5, 1.0, 1.0, 2.0, 1.5, 1.5, 1.125, 1.0, 2.6666666666666665, 1.2857142857142858, 0.8888888888888888, 0.9090909090909091, 2.111111111111111, 63.42857142857143, 1.0, 1.0, 3.0, 1.0, 1.0, 1.125, 1.0, 3.0, 1.125, 1.0, 1.3333333333333333, 2.4, 1.0, 1.125, 1.0, 1.0, 1.7, 1.0, 2.3, 1.75, 2.0, 89.75, 49.8, 1.125, 2.1818181818181817, 62.25, 1.0, 2.0, 1.0, 1.0, 2.4, 3.0, 4.0, 1.0, 1.8888888888888888, 1.5, 1.0, 1.6666666666666667, 2.2, 1.0, 1.0, 1.125, 1.0, 1.125, 1.0, 1.0, 3.1666666666666665, 2.6666666666666665, 1.0, 3.0, 3.0, 0.8888888888888888, 3.2857142857142856, 0.9090909090909091, 1.0, 1.5555555555555556, 1.0, 1.25, 2.875, 3.0, 1.6, 1.0, 2.1818181818181817, 1.0, 1.75, 3.0, 1.7777777777777777, 1.0, 1.3333333333333333, 1.0, 2.6666666666666665, 1.125, 3.2857142857142856, 1.8, 1.6, 1.9, 3.0, 1.0, 2.375, 1.0, 1.0, 1.0, 1.2727272727272727, 1.0, 1.125, 2.375, 1.0, 1.6, 1.125, 1.5, 1.5, 1.125, 1.0, 1.0, 0.9, 1.4545454545454546, 1.0, 1.0, 1.0, 1.125, 2.375, 1.5, 1.0, 4.0, 2.3333333333333335, 3.0, 1.125, 1.0, 1.2857142857142858, 2.5555555555555554, 1.0, 2.4444444444444446, 3.4285714285714284]\n",
      "3.5783439893439897\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/transcribe/t15_noisy.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.375, 1.0, 2.1, 1.0, 1.3846153846153846, 1.875, 1.0, 1.0, 1.5, 1.0, 44.3, 1.0, 1.0, 1.0, 1.7, 1.375, 1.0, 1.2727272727272727, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.2307692307692308, 1.0, 1.0, 2.8333333333333335, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 40.36363636363637, 1.0, 1.0, 1.0, 1.0, 1.0, 1.25, 1.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.5, 1.0, 1.0, 1.4, 1.7, 1.0, 55.5, 1.625, 1.0, 1.0, 1.0, 2.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.8333333333333335, 0.0, 1.0, 1.0, 1.0, 3.3333333333333335, 1.0, 1.2727272727272727, 1.0, 0.0, 55.5, 1.0, 1.0, 1.0, 1.0, 1.5, 1.0, 1.0, 2.5, 1.0, 1.5555555555555556, 1.2727272727272727, 1.0, 2.7142857142857144, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.375, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.625, 1.0, 1.0, 1.0, 1.0, 2.125, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.1666666666666667, 1.0, 1.0, 1.7, 1.0, 1.0, 2.75, 1.0, 1.5, 1.0, 1.7777777777777777, 1.0, 1.0, 2.0, 1.0, 2.25, 1.8888888888888888, 1.0, 1.0, 1.0, 2.3333333333333335, 1.0, 1.0, 1.0, 1.0, 1.5, 1.0, 1.0, 1.0, 1.875, 83.125, 1.0, 1.0, 1.6666666666666667, 1.0, 1.0, 1.0, 1.0, 1.8, 1.0, 1.0, 1.0, 1.0, 1.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 50.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.6923076923076923, 1.25, 2.375, 55.5, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 2.0, 49.44444444444444, 1.5454545454545454, 2.3333333333333335, 1.0]\n",
      "3.091552225552226\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/transcribe/t15_AEC.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/transcribe/t0_noisy_vad.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/transcribe/t0_AEC_vad.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.6, 0.42857142857142855, 0.75, 1.0, 1.0, 0.5454545454545454, 0.375, 0.25, 0.2222222222222222, 0.2, 0.7777777777777778, 0.38461538461538464, 1.0, 0.3333333333333333, 0.2857142857142857, 0.5, 0.8, 0.7, 0.0, 0.25, 0.5, 0.6, 0.5, 1.0, 0.6363636363636364, 0.6363636363636364, 0.25, 0.375, 0.5, 0.3, 1.0, 0.6666666666666666, 0.5, 0.6666666666666666, 0.5555555555555556, 0.7272727272727273, 0.7777777777777778, 0.4, 0.8181818181818182, 0.6923076923076923, 0.8333333333333334, 0.5, 1.3333333333333333, 1.0, 0.3333333333333333, 0.2222222222222222, 0.3333333333333333, 0.0, 1.0, 0.25, 0.42857142857142855, 0.4444444444444444, 0.2727272727272727, 0.6666666666666666, 0.42857142857142855, 0.75, 0.0, 0.5, 0.125, 1.0, 0.5, 0.18181818181818182, 1.0, 0.25, 0.0, 0.2, 0.0, 0.46153846153846156, 0.5, 0.3333333333333333, 0.5714285714285714, 0.1, 0.0, 0.7, 0.25, 0.25, 0.4, 0.0, 0.25, 0.75, 0.18181818181818182, 0.25, 0.45454545454545453, 0.125, 0.0, 0.25, 0.1, 1.0, 0.0, 0.25, 0.2222222222222222, 0.6363636363636364, 0.4444444444444444, 0.5, 0.36363636363636365, 0.38461538461538464, 0.25, 0.5, 0.3333333333333333, 0.0, 0.0, 0.0, 0.16666666666666666, 0.25, 0.875, 0.0, 0.42857142857142855, 0.3333333333333333, 0.36363636363636365, 0.3333333333333333, 0.42857142857142855, 0.625, 0.6, 0.75, 0.375, 0.9, 0.75, 0.9090909090909091, 1.0, 0.25, 0.4444444444444444, 0.8888888888888888, 0.2, 0.6923076923076923, 0.5, 1.0, 0.8571428571428571, 1.0, 0.9, 0.6, 0.625, 0.25, 0.5, 0.6, 0.625, 0.18181818181818182, 1.0, 0.8181818181818182, 0.25, 0.5, 0.0, 0.4, 0.25, 0.16666666666666666, 0.875, 0.8888888888888888, 0.0, 0.6363636363636364, 0.7777777777777778, 1.0, 0.6363636363636364, 0.8333333333333334, 0.5, 0.9230769230769231, 0.0, 0.0, 0.6666666666666666, 0.5, 0.6666666666666666, 0.5, 0.5, 0.25, 0.3333333333333333, 0.5714285714285714, 0.45454545454545453, 0.7142857142857143, 0.2222222222222222, 0.2, 0.75, 0.75, 0.875, 0.9, 0.375, 0.2727272727272727, 0.375, 0.125, 0.75, 0.0, 0.2, 0.5555555555555556, 0.5384615384615384, 1.0, 0.5, 0.7142857142857143, 0.4, 0.7, 0.7, 0.625, 0.375, 0.25, 0.0, 0.4, 0.25, 0.45454545454545453, 0.2727272727272727, 0.125, 0.125, 0.5, 0.7, 0.25, 0.16666666666666666, 0.8333333333333334, 0.5, 0.5555555555555556, 0.4444444444444444, 0.2, 0.36363636363636365, 0.9090909090909091, 0.6923076923076923, 0.9166666666666666, 0.75, 0.5, 0.0, 0.5555555555555556, 0.0, 1.0, 0.0, 0.25, 0.25, 0.42857142857142855, 0.5555555555555556, 0.36363636363636365, 0.3333333333333333, 0.42857142857142855]\n",
      "0.47739250872584205\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/transcribe/t0_noisy_google.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 0.8, 0.42857142857142855, 0.5, 1.0, 1.0, 0.5454545454545454, 0.375, 0.75, 0.6666666666666666, 0.2, 0.6666666666666666, 0.6923076923076923, 1.0, 0.3333333333333333, 0.2857142857142857, 0.5, 0.7, 0.7, 0.0, 0.25, 0.5, 0.6, 0.5, 1.0, 0.8181818181818182, 0.6363636363636364, 0.25, 0.25, 0.5, 0.4, 1.0, 0.3333333333333333, 0.5, 1.0, 0.2222222222222222, 1.0, 0.2222222222222222, 0.4, 0.7272727272727273, 0.8461538461538461, 0.9166666666666666, 0.75, 0.0, 0.25, 0.3333333333333333, 0.2222222222222222, 0.8333333333333334, 0.0, 1.0, 0.25, 0.42857142857142855, 0.5555555555555556, 0.36363636363636365, 0.3333333333333333, 0.2857142857142857, 0.125, 0.0, 1.0, 0.625, 1.0, 0.5, 0.2727272727272727, 1.0, 0.25, 0.0, 0.2, 0.0, 0.46153846153846156, 0.5, 0.3333333333333333, 0.42857142857142855, 0.1, 0.0, 0.0, 0.25, 0.5, 0.4, 0.0, 0.25, 1.0, 0.18181818181818182, 0.5, 0.45454545454545453, 0.625, 0.0, 0.0, 0.2, 1.0, 0.0, 0.25, 0.2222222222222222, 0.6363636363636364, 0.4444444444444444, 0.2, 0.18181818181818182, 0.15384615384615385, 0.375, 1.125, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.25, 0.5, 0.0, 0.42857142857142855, 0.3333333333333333, 0.36363636363636365, 0.8888888888888888, 0.42857142857142855, 0.875, 0.6, 1.0, 0.375, 1.0, 0.375, 0.2727272727272727, 1.0, 0.25, 0.6666666666666666, 0.5555555555555556, 1.0, 0.9230769230769231, 1.0, 1.0, 0.8571428571428571, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.25, 0.18181818181818182, 1.0, 0.7272727272727273, 0.25, 0.5, 0.25, 0.3, 0.25, 0.8333333333333334, 0.75, 1.0, 0.0, 0.9090909090909091, 0.7777777777777778, 0.6, 0.6363636363636364, 0.9166666666666666, 0.5, 1.0, 0.75, 0.0, 0.6666666666666666, 0.0, 0.8333333333333334, 1.0, 1.0, 1.0, 0.5555555555555556, 0.5714285714285714, 0.6363636363636364, 1.0, 0.4444444444444444, 0.6, 1.0, 0.25, 0.5, 0.7, 0.5, 0.8181818181818182, 0.375, 0.375, 1.0, 0.3333333333333333, 0.8, 0.6666666666666666, 0.5384615384615384, 1.0, 0.75, 0.7142857142857143, 0.8, 1.0, 0.8, 0.625, 0.25, 0.25, 0.25, 0.4, 0.25, 0.45454545454545453, 0.6363636363636364, 0.25, 0.5, 0.5, 0.9, 0.5, 0.3333333333333333, 1.0, 0.5, 0.5555555555555556, 1.0, 0.8, 0.8181818181818182, 0.8181818181818182, 1.0, 0.9166666666666666, 0.5, 0.0, 0.0, 0.5555555555555556, 0.0, 1.0, 0.3333333333333333, 0.25, 1.0, 0.42857142857142855, 1.0, 0.36363636363636365, 0.5555555555555556, 0.2857142857142857]\n",
      "0.5357146803813471\n"
     ]
    }
   ],
   "source": [
    "compare_txt = \"/home/nas3/user/thk/TRANet/transcribe/t0_AEC_google.txt\"\n",
    "CER_result = []\n",
    "with open(compare_txt, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split(\":\")\n",
    "        file_name = line[0]\n",
    "        transcribe = line[1].lstrip()\n",
    "        label = label_transcribe[file_name.split(\"_Noise\")[0]]\n",
    "        \n",
    "        dist, length = CER.metric(label, transcribe)\n",
    "        cer = dist / length\n",
    "        CER_result.append(cer)\n",
    "        \n",
    "mean_CER = np.mean(CER_result)\n",
    "print(CER_result)\n",
    "print(mean_CER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ver38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
